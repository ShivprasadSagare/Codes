{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import math\n",
    "import torch\n",
    "from torch.nn import Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(query: str, docs: list) -> float:\n",
    "    \"\"\"An implementation of 'practical scoring function' originally from lucene, adapted to our needs.\n",
    "    \n",
    "    Consists of term frequency, query coordination factor, id, field-length norm. \n",
    "    queryNorm, boost are skipped.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    query : str\n",
    "        The word from the sentence.\n",
    "    docs : list\n",
    "        list of values from triples. Each value is a object string from triple.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        list of matching scores for each of the doc in the docs list\n",
    "    \"\"\"\n",
    "\n",
    "    scores = []\n",
    "    \n",
    "    query_tok = word_tokenize(query)\n",
    "    docs_tok = [word_tokenize(doc) for doc in docs]\n",
    "    \n",
    "    # idf: list stores idf values for each term in query. idf values are used later in code.\n",
    "    idf_scores = []\n",
    "    for tok in query_tok:\n",
    "        doc_freq = sum([1 for doc in docs_tok if tok in doc])\n",
    "        idf = 1 + math.log(len(docs)/(doc_freq + 1))\n",
    "        idf_scores.append(idf)\n",
    "    \n",
    "    for doc in docs:\n",
    "        doc_tok = word_tokenize(doc)\n",
    "        score = 0\n",
    "        for id, term in enumerate(query_tok):\n",
    "            tf = sum([1 for tok in doc_tok if tok==term])\n",
    "            idf = idf_scores[id]\n",
    "            norm = 1 / len(doc)\n",
    "            score += tf * idf * norm\n",
    "        query_coord = sum([1 for tok in query_tok if tok in doc]) / len(query_tok)\n",
    "        score *= query_coord\n",
    "        scores.append(score)\n",
    "    \n",
    "    return scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'cricketer 2020'\n",
    "docs = ['cricketer 2020', 'footballer', 'cricketer of the year 2020']\n",
    "result = score(query=query, docs=docs)\n",
    "# result = torch.tensor(result)\n",
    "# S = Softmax(dim=-1)\n",
    "# S(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd0d782713032c239be331c9ea6d054a3c886f04ae6d19082ca5dd54216e8bc8"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
